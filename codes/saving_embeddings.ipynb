{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(embeddings, file_name):\n",
    "    np.save(file_name, embeddings)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KLUE/roberta-base\")\n",
    "model = AutoModel.from_pretrained(\"KLUE/roberta-base\")\n",
    "questions_df = pd.read_csv(\"/home/fastcampus/Gasan/only_question.csv\")\n",
    "questions = questions_df[\"질문\"].tolist()\n",
    "high_similarity_questions =[]\n",
    "questions_embedding_list=[]\n",
    "def get_sentence_embedding(sentence):\n",
    "    if not isinstance(sentence, str) or not sentence.strip():\n",
    "        # Return an empty array if the sentence is not valid.\n",
    "        return np.array([])\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(axis=1).detach().numpy()\n",
    "    return embeddings.reshape(-1)\n",
    "for question in questions:\n",
    "    embedding = get_sentence_embedding(question)\n",
    "    if embedding.size > 0:\n",
    "        questions_embedding_list.append(embedding)\n",
    "questions_embedding_array = np.array(questions_embedding_list)\n",
    "save_embeddings(questions_embedding_array, \"questions_embeddings.npy\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
