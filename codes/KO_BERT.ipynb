{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f538c54a32074ef1a7352ae9ba4f4261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f483ee71e76f4a699c316173a41c661a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecbb9683d2c4cd68314db6c2d80799a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f6cb5834da46369ffb06dadfc60925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 768 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m sentence1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m이 음식은 맛있어.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m sentence2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m이 식사는 맛있어요.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m similarity_score \u001b[39m=\u001b[39m sentence_similarity(sentence1, sentence2)\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe similarity score between the two sentences is:\u001b[39m\u001b[39m\"\u001b[39m, similarity_score)\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36msentence_similarity\u001b[0;34m(sentence1, sentence2)\u001b[0m\n\u001b[1;32m     15\u001b[0m     model_output2 \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_input2)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Calculate the cosine similarity of the sentences' embeddings\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m cosine_sim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcosine_similarity(model_output1[\u001b[39m0\u001b[39;49m], model_output2[\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m cosine_sim\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 768 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "    model = AutoModel.from_pretrained(\"monologg/kobert\")\n",
    "\n",
    "    # Tokenize the input sentences\n",
    "    encoded_input1 = tokenizer(sentence1, return_tensors='pt')\n",
    "    encoded_input2 = tokenizer(sentence2, return_tensors='pt')\n",
    "    \n",
    "    # Get the embeddings of the input sentences\n",
    "    with torch.no_grad():\n",
    "        model_output1 = model(**encoded_input1)\n",
    "        model_output2 = model(**encoded_input2)\n",
    "\n",
    "    # Calculate the cosine similarity of the sentences' embeddings\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(model_output1[0], model_output2[0]).item()\n",
    "\n",
    "    return cosine_sim\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"이 음식은 맛있어.\"\n",
    "sentence2 = \"이 식사는 맛있어요.\"\n",
    "\n",
    "similarity_score = sentence_similarity(sentence1, sentence2)\n",
    "\n",
    "print(\"The similarity score between the two sentences is:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertModel' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     19\u001b[0m given_sentences \u001b[39m=\u001b[39m [\n\u001b[1;32m     20\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m2019년 3월에 급격한 비급여매출 증가가 있었는데, 그 원인은 무엇일까요?\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m2019년 7월과 2019년 10월에 비급여매출이 매우 높은 것으로 나타났는데, 해당 월에 어떠한 사업 전략이 있었을까요?\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m비급여매출 증가의 원인 중 국내외의 경제 상황은 어떤 영향을 미쳤을까요?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m     ]\n\u001b[1;32m     27\u001b[0m \u001b[39m# Encode the base and given sentences\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m base_embeddings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(base_sentences, convert_to_tensor\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m given_embeddings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode(given_sentences, convert_to_tensor\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Calculate cosine similarities\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertModel' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import PreTrainedTokenizer, PreTrainedModel, BertTokenizer, BertModel\n",
    "\n",
    "# Load the KO-BERT model\n",
    "model = SentenceTransformer('kykim/bert-kor-base')\n",
    "\n",
    "# CSV file path\n",
    "csv_file = '/home/fastcampus/Seokjun/csv/only_q.csv'\n",
    "\n",
    "# Read base sentences from CSV\n",
    "base_sentences = []\n",
    "with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        base_sentences.append(row[0])  # Assuming the sentence is in the first column of the CSV\n",
    "\n",
    "# Given sentences\n",
    "given_sentences = [\n",
    "    \"2019년 3월에 급격한 비급여매출 증가가 있었는데, 그 원인은 무엇일까요?\",\n",
    "    \"2019년 7월과 2019년 10월에 비급여매출이 매우 높은 것으로 나타났는데, 해당 월에 어떠한 사업 전략이 있었을까요?\",\n",
    "    \"2018년 10월과 2019년 1월에 비급여매출이 급증한 이유는 무엇일까요?\",\n",
    "    \"2020년 2월에 비급여매출이 크게 증가한 이유를 파악할 수 있을까요?\",\n",
    "    \"비급여매출 증가의 원인 중 국내외의 경제 상황은 어떤 영향을 미쳤을까요?\"\n",
    "    ]\n",
    "\n",
    "# Encode the base and given sentences\n",
    "base_embeddings = model.encode(base_sentences, convert_to_tensor=True)\n",
    "given_embeddings = model.encode(given_sentences, convert_to_tensor=True)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "similarities = util.cos_sim(given_embeddings, base_embeddings)\n",
    "\n",
    "# Print the top 5 most similar base sentences for each given sentence\n",
    "for i, given_sentence in enumerate(given_sentences):\n",
    "    print(f\"Top 5 most similar base sentences for '{given_sentence}':\")\n",
    "    similarity_scores = similarities[i]\n",
    "    num_similarities = min(5, len(similarity_scores))\n",
    "    top_indices = similarity_scores.argsort()[-num_similarities:][::-1]  # Indices of top similarities in descending order\n",
    "    for idx in top_indices:\n",
    "        base_sentence = base_sentences[idx]\n",
    "        similarity = similarity_scores[idx].item()\n",
    "        print(f\"Base sentence '{base_sentence}': {similarity}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (13) must match the size of tensor b (31) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     25\u001b[0m         model_output2 \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_input2)\n\u001b[0;32m---> 26\u001b[0m     similarity \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcosine_similarity(model_output[\u001b[39m0\u001b[39;49m], model_output2[\u001b[39m0\u001b[39;49m], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     27\u001b[0m     similarities\u001b[39m.\u001b[39mappend(similarity)\n\u001b[1;32m     29\u001b[0m \u001b[39m# 유사도가 높은 상위 5개의 기존 문장 출력\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (13) must match the size of tensor b (31) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# CSV 파일에서 데이터 로드\n",
    "data = pd.read_csv('/home/fastcampus/Seokjun/csv/only_q.csv')\n",
    "\n",
    "# KoBERT 모델 및 tokenizer 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "model = AutoModel.from_pretrained(\"monologg/kobert\")\n",
    "\n",
    "# 새로운 문장 입력\n",
    "new_sentence = \"2019년 3월에 급격한 비급여매출 증가가 있었는데, 그 원인은 무엇일까요?\"\n",
    "\n",
    "# 입력 문장의 임베딩 계산\n",
    "encoded_input = tokenizer(new_sentence, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# 새로운 문장과 기존 문장들 간의 유사도 계산\n",
    "similarities = []\n",
    "for i, row in data.iterrows():\n",
    "    encoded_input2 = tokenizer(row['질문'], return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output2 = model(**encoded_input2)\n",
    "    similarity = torch.nn.functional.cosine_similarity(model_output[0], model_output2[0], dim=1).item()\n",
    "    similarities.append(similarity)\n",
    "\n",
    "# 유사도가 높은 상위 5개의 기존 문장 출력\n",
    "similarities_df = pd.DataFrame({'질문': data['질문'], '유사도': similarities})\n",
    "top_5 = similarities_df.nlargest(5, '유사도')\n",
    "print(\"새로운 문장: \", new_sentence)\n",
    "print(\"상위 5개의 기존 문장: \")\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KLUE/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KLUE/bert-base\")\n",
    "model = AutoModel.from_pretrained(\"KLUE/bert-base\")\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    if not isinstance(sentence, str):\n",
    "        #print(\"문장은 문자열로 입력해주세요.\")\n",
    "        pass\n",
    "        return None\n",
    "\n",
    "    if not sentence.strip():\n",
    "        #print(\"비어있는 문자열은 처리할 수 없습니다.\")\n",
    "        pass\n",
    "        return None\n",
    "\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(axis=1).detach().numpy()\n",
    "    return embeddings.reshape(-1)\n",
    "\n",
    "input_questions = [\n",
    "    \"2019년 3월에 급격한 비급여매출 증가가 있었는데, 그 원인은 무엇일까요?\",\n",
    "    \"2019년 7월과 2019년 10월에 비급여매출이 매우 높은 것으로 나타났는데, 해당 월에 어떠한 사업 전략이 있었을까요?\",\n",
    "    \"2018년 10월과 2019년 1월에 비급여매출이 급증한 이유는 무엇일까요?\",\n",
    "    \"2020년 2월에 비급여매출이 크게 증가한 이유를 파악할 수 있을까요?\",\n",
    "    \"비급여매출 증가의 원인 중 국내외의 경제 상황은 어떤 영향을 미쳤을까요?\"\n",
    "    ]\n",
    "\n",
    "questions_df = pd.read_csv(\"/home/fastcampus/Seoknam/only_question.csv\")\n",
    "questions = questions_df[\"질문\"].tolist()\n",
    "\n",
    "def get_top5_similar_questions(embed_question, questions):\n",
    "    if embed_question is None:\n",
    "        return [], []\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for question in questions:\n",
    "        embed = get_sentence_embedding(question)\n",
    "        if embed is not None:\n",
    "            similarity = 1 - cosine(embed_question, embed)\n",
    "        else:\n",
    "            similarity = 0\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    top5_indexes = np.argsort(similarities)[-5:][::-1]\n",
    "    top5_questions = [questions[i] for i in top5_indexes]\n",
    "    top5_similarities = [similarities[i] for i in top5_indexes]\n",
    "\n",
    "    return top5_questions, top5_similarities\n",
    "\n",
    "def print_top5_similar_questions(input_question, embed_input_question, questions):\n",
    "    top5_questions, top5_similarities = get_top5_similar_questions(embed_input_question, questions)\n",
    "\n",
    "    print(f\"\\n{input_question}와 가장 유사한 5개 질문:\")\n",
    "    for i, (question, similarity) in enumerate(zip(top5_questions, top5_similarities)):\n",
    "        print(f\"Top{i + 1} 유사 질문: {question} (유사도: {similarity:.2f})\")\n",
    "\n",
    "for input_question in input_questions:\n",
    "    embed_input_question = get_sentence_embedding(input_question)\n",
    "    print_top5_similar_questions(input_question, embed_input_question, questions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
